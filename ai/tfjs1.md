# TensorFlow.jsæœºå™¨å­¦ä¹ æ•™ç¨‹(1) - ç©¿æ¢­äºæµè§ˆå™¨ä¸nodeé—´

![](https://gw.alicdn.com/imgextra/i4/O1CN01SvbpK71x8KjVYFTqY_!!6000000006398-0-tps-1254-552.jpg)

å‰ç«¯åŒå­¦å­¦ä¹ æœºå™¨å­¦ä¹ ï¼Œé¢å¯¹æ±—ç‰›å……æ ‹çš„åŸºäºPythonçš„å„ç§æ•™ç¨‹ï¼Œè™½ç„¶ä¸è§å¾—ä¸æ‡‚Pythonï¼Œä½†æ˜¯å› ä¸ºä¸æ˜¯åç«¯ï¼Œæƒ³æŠŠå­¦åˆ°çš„çŸ¥è¯†ç”¨åˆ°å·¥ä½œä¸­è¿˜æ˜¯æœ‰ä¸€æ®µè·ç¦»ã€‚
Pythonç¡®å®åœ¨æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ é¢†åŸŸæœ‰ç€ä¸å¯æ›¿ä»£çš„ç”Ÿæ€ä¼˜åŠ¿ï¼Œä¸è¿‡ï¼Œæ”¾åˆ°æµè§ˆå™¨ç«¯å’Œæ‰‹æœºç«¯ï¼ŒPythonçš„ç”Ÿæ€ä¼˜åŠ¿å¥½åƒå°±å‘æŒ¥ä¸å‡ºæ¥äº†ã€‚ä¸ç®¡æ˜¯Androidæ‰‹æœºè¿˜æ˜¯iOSæ‰‹æœºï¼Œé»˜è®¤éƒ½æ²¡æœ‰Pythonè¿è¡Œç¯å¢ƒï¼Œä¹Ÿå†™ä¸äº†Pythonåº”ç”¨ã€‚æµè§ˆå™¨é‡Œå’Œå°ç¨‹åºé‡Œï¼Œå°±æ›´æ²¡Pythonä»€ä¹ˆäº‹å„¿äº†ã€‚

åœ¨æµè§ˆå™¨é‡Œï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨TensorFlow.jsåº“ï¼Œå°½ç®¡å¯èƒ½ä¼šæœ‰æ€§èƒ½çš„é—®é¢˜ï¼Œä½†æ˜¯è‡³å°‘æ˜¯ä»0åˆ°1çš„çªç ´ã€‚

æˆ‘ä»¬çœ‹ä¸ªä¾‹å­ï¼š
```html
<!DOCTYPE html>
<html>
    <head>
        <meta encoding="UTF-8"/>
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.6.0/dist/tf.min.js"></script>
    </head>
    <body>
        <div id="tf-display"></div>
        <script>
            let a = tf.tensor1d([1.0]);
            let d1 = document.getElementById("tf-display");
            d1.innerText = a;
        </script>
    </body>
</html>
```

å¯ä»¥çœ‹åˆ°ï¼Œåœ¨æµè§ˆå™¨é‡Œæ˜¾ç¤ºäº†ä¸€ä¸ªå€¼ä¸º1.0çš„å¼ é‡çš„å€¼ã€‚æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªTensorFlow.js(ä»¥ä¸‹ç®€ç§°tf.js)åº”ç”¨å°±ç®—æ˜¯è·‘é€šäº†ã€‚é€šè¿‡å¼•ç”¨tf.jsçš„åº“ï¼Œæˆ‘ä»¬å°±å¯ä»¥è°ƒç”¨tfä¸‹é¢çš„å‡½æ•°ã€‚

ä¸‹é¢æˆ‘ä»¬ä¿®æ”¹ä¸€ä¸‹ï¼Œçœ‹çœ‹tf.jsæ˜¯é ä»€ä¹ˆæŠ€æœ¯åœ¨è¿è¡Œçš„ã€‚æˆ‘ä»¬é€šè¿‡tf.getBackend()å‡½æ•°æ¥æŸ¥çœ‹æ”¯æŒtf.js

```html
<!DOCTYPE html>
<html>
    <head>
        <meta encoding="UTF-8"/>
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.6.0/dist/tf.min.js"></script>
    </head>
    <body>
        <div id="tf-display"></div>
        <div id="tf-backend"></div>
        <script>
            let a = tf.tensor1d([1.0,2.0,3.0]);
            let d1 = document.getElementById("tf-display");
            d1.innerText = a;

            let backend = tf.getBackend();
            let div_backend = document.getElementById("tf-backend");
            div_backend.innerText = backend;
        </script>
    </body>
</html>
```

åœ¨æˆ‘çš„æµè§ˆå™¨é‡Œï¼Œtf.jsæ˜¯ä½¿ç”¨webglæ¥è¿›è¡Œè®¡ç®—çš„ã€‚

## è¿è¡Œåœ¨nodeé‡Œçš„tfjs

ä½œä¸ºä¸€ä¸ªjsåº“ï¼Œtf.jså½“ç„¶ä¹Ÿå¯ä»¥è¿è¡Œåœ¨nodeç¯å¢ƒé‡Œã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡
```
npm install @tensorflow/tfjs
```
æ¥å®‰è£…tf.jsåº“ã€‚

ç„¶åæŠŠä¸Šé¢ç½‘é¡µé‡Œé¢çš„ä»£ç ç§»å€¼è¿‡æ¥ï¼š
```js
const tf = require('@tensorflow/tfjs');

let a = tf.tensor1d([1.0,2.0,3.0]);
console.log(a);

console.log(tf.getBackend());
```

åœ¨æˆ‘çš„ç”µè„‘é‡Œæ‰§è¡Œï¼Œè¿™ä¸ªgetBackend()è¿”å›çš„æ˜¯'cpu'. 
tf.jsè¿˜ä¼šç»™tfjs-nodeåšä¸ªå¹¿å‘Šï¼š
```
============================
Hi there ğŸ‘‹. Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, which binds to TensorFlow C++, by running npm i @tensorflow/tfjs-node, or npm i @tensorflow/tfjs-node-gpu if you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffix for CUDA) at the start of your program. Visit https://github.com/tensorflow/tfjs-node for more details.
============================
```

å¬äººåŠåƒé¥±é¥­ï¼Œé‚£æˆ‘ä»¬å°±æ¢æˆtfjs-nodeå§ï¼š

```js
const tf = require('@tensorflow/tfjs-node');

let a = tf.tensor1d([1.0,2.0,3.0]);
console.log(a);

console.log(tf.getBackend());
```

è®°å¾—è¦
```
npm install @tensorflow/tfjs-node
```

ç°åœ¨ï¼Œåç«¯ä»cpuæ¢æˆäº†tensorflowã€‚

è¿˜æœ‰æ›´å‡¶æ®‹çš„ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥æ¢æˆtfjs-node-gpuæ¥ä½¿ç”¨GPUï¼š
```js
const tf = require('@tensorflow/tfjs-node-gpu');

let a = tf.tensor1d([1.0,2.0,3.0]);
console.log(a);

console.log(tf.getBackend());
```
åœ¨æ²¡æœ‰GPUçš„æœºå™¨ä¸Šï¼Œä¼šä½¿ç”¨CPUç‰ˆçš„tensorflowä½œä¸ºåç«¯ï¼Œä¸ä¼šæŠ¥é”™ã€‚

## ä½¿ç”¨tfjsé¢„æµ‹æ³¢å£«é¡¿æˆ¿ä»·

æŒ‰ç…§å›½é™…æƒ¯ä¾‹ï¼Œæˆ‘ä»¬çš„tfjsæœºå™¨å­¦ä¹ ä¹‹æ—…ä¹Ÿä»é¢„æµ‹æˆ¿ä»·å¼€å§‹ã€‚

æˆ‘ä»¬å…ˆæä¸ªnodeé‡Œè¿è¡Œçš„ç‰ˆæœ¬ï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥ä½¿ç”¨tf.data.csvå»è¯»å–csvæ•°æ®ã€‚è€Œåœ¨æµè§ˆå™¨é‡Œï¼Œæˆ‘ä»¬å°±å¾—æ±‚åŠ©äºå¼ºå¤§çš„papaparserä¹‹ç±»çš„åº“äº†ã€‚

é¦–å…ˆæˆ‘ä»¬å…ˆæŒ‡å®šæ•°æ®çš„URLï¼Œç›´æ¥ä¸ºç½‘ä¸Šçš„åœ°å€ï¼š
```js
const csvUrl =
    'https://storage.googleapis.com/tfjs-examples/multivariate-linear-regression/data/boston-housing-train.csv';
```

æˆ‘ä»¬è¦é¢„æµ‹çš„æ˜¯æˆ¿ä»·ä¸­ä½æ•°medvå­—æ®µï¼Œå…ˆå®šä¹‰å¥½ï¼š
```js
    const csvDataset = tf.data.csv(
        csvUrl, {
            columnConfigs: {
                medv: {
                    isLabel: true
                }
            }
        });
```

ç„¶åè½¬æ¢ä¸€ä¸‹æ ¼å¼ï¼š
```js
    // Number of features is the number of column names minus one for the label
    // column.
    const numOfFeatures = (await csvDataset.columnNames()).length - 1;

    // Prepare the Dataset for training.
    const flattenedDataset =
        csvDataset
            .map(({xs, ys}) =>
            {
                // Convert xs(features) and ys(labels) from object form (keyed by
                // column name) to array form.
                return {xs:Object.values(xs), ys:Object.values(ys)};
            })
            .batch(10);
```

çº¿æ€§å›å½’å°±æ˜¯æ²¡æœ‰éšè—å±‚çš„ä¸€å±‚ã€‚è¾“å…¥æ˜¯numOfFeaturesä¸ªå…ƒç´ ï¼Œè¾“å‡ºæ˜¯1ä¸ªå…ƒç´ ï¼š
```js
    const model = tf.sequential();
    model.add(tf.layers.dense({
        inputShape: [numOfFeatures],
        units: 1
    }));
```

æœ€åè®¾ç½®ä¼˜åŒ–ç®—æ³•ã€å­¦ä¹ ç‡ç­‰å‚æ•°ï¼Œç¼–è¯‘è¿è¡Œå°±å¥½äº†ï¼š
```js
    model.compile({
        optimizer: tf.train.sgd(0.000001),
        loss: 'meanSquaredError'
    });

    return model.fitDataset(flattenedDataset, {
        epochs: 10,
        callbacks: {
            onEpochEnd: async (epoch, logs) => {
                console.log(epoch + ':' + logs.loss);
            }
        }
    });
```

å…¶ä¸­è¯´ä¸€ä¸‹callbackså§ï¼Œæ”¯æŒä¸€äº›ç”Ÿå‘½å‘¨æœŸçš„å›è°ƒã€‚é™¤äº†onEpochEndï¼Œè¿˜æœ‰onEpochBegin, onTrainBegin, onTrainEndç­‰ï¼š

```js
    return model.fitDataset(flattenedDataset, {
        epochs: 10,
        callbacks: {
            onEpochEnd: async (epoch, logs) => {
                console.log(epoch + ':' + logs.loss);
            },
            onTrainBegin: async(logs) => {
                console.log("Train Begin!");
            },
            onTrainEnd: async(logs) => {
                console.log('Train End!');
            }
        }
    });
```

ç”¨Nodeè¿è¡Œï¼Œå°±å¯ä»¥çœ‹åˆ°è®­ç»ƒçš„è¿‡ç¨‹äº†ï¼š
```
Train Begin!
Epoch 1 / 10
eta=0.0 ================================================================================> 
1124ms 41639us/step - loss=1445.89 
0:1445.89404296875
Epoch 2 / 10
eta=0.0 ================================================================================> 
1002ms 37093us/step - loss=254.11 
1:254.1094970703125
Epoch 3 / 10
eta=0.0 ================================================================================> 
989ms 36618us/step - loss=250.23 
2:250.233642578125
Epoch 4 / 10
eta=0.0 ================================================================================> 
965ms 35746us/step - loss=246.57 
3:246.57472229003906
Epoch 5 / 10
eta=0.0 ================================================================================> 
974ms 36056us/step - loss=243.12 
4:243.11817932128906
Epoch 6 / 10
eta=0.0 ================================================================================> 
955ms 35358us/step - loss=239.85 
5:239.85049438476562
Epoch 7 / 10
eta=0.0 ================================================================================> 
963ms 35659us/step - loss=236.76 
6:236.75921630859375
Epoch 8 / 10
eta=0.0 ================================================================================> 
942ms 34904us/step - loss=233.83 
7:233.83265686035156
Epoch 9 / 10
eta=0.0 ================================================================================> 
963ms 35650us/step - loss=231.06 
8:231.05992126464844
Epoch 10 / 10
eta=0.0 ================================================================================> 
920ms 34064us/step - loss=228.43 
9:228.43093872070312
Train End!
```

å®Œæ•´çš„ä»£ç å¦‚ä¸‹ï¼š
```js
const tf = require('@tensorflow/tfjs-node');

const csvUrl =
    'https://storage.googleapis.com/tfjs-examples/multivariate-linear-regression/data/boston-housing-train.csv';

async function run() {
    // We want to predict the column "medv", which represents a median value of
    // a home (in $1000s), so we mark it as a label.
    const csvDataset = tf.data.csv(
        csvUrl, {
            columnConfigs: {
                medv: {
                    isLabel: true
                }
            }
        });

    // Number of features is the number of column names minus one for the label
    // column.
    const numOfFeatures = (await csvDataset.columnNames()).length - 1;

    // Prepare the Dataset for training.
    const flattenedDataset =
        csvDataset
            .map(({xs, ys}) =>
            {
                // Convert xs(features) and ys(labels) from object form (keyed by
                // column name) to array form.
                return {xs:Object.values(xs), ys:Object.values(ys)};
            })
            .batch(10);

    // Define the model.
    const model = tf.sequential();
    model.add(tf.layers.dense({
        inputShape: [numOfFeatures],
        units: 1
    }));
    model.compile({
        optimizer: tf.train.sgd(0.000001),
        loss: 'meanSquaredError'
    });

    // Fit the model using the prepared Dataset
    return model.fitDataset(flattenedDataset, {
        epochs: 10,
        callbacks: {
            onEpochEnd: async (epoch, logs) => {
                console.log(epoch + ':' + logs.loss);
            },
            onTrainBegin: async(logs) => {
                console.log("Train Begin!");
            },
            onTrainEnd: async(logs) => {
                console.log('Train End!');
            }
        }
    });
}

run();
```


## åœ¨æµè§ˆå™¨é‡Œé¢„æµ‹æ³¢å£«é¡¿æˆ¿ä»·

![boston](https://gw.alicdn.com/imgextra/i3/O1CN018HUiij1VBG17MSrnF_!!6000000002614-2-tps-1240-727.png)

è¿è¡Œåœ¨æµè§ˆå™¨é‡Œï¼Œä¸Šé¢çš„æ ¸å¿ƒç®—æ³•éƒ½ä¸ç”¨å˜ï¼Œåªæ˜¯å¯¹æ•°æ®å¤„ç†å’ŒUIçš„éƒ¨åˆ†è¦å¤æ‚ä¸€äº›ã€‚

csvè¯»å–æˆ‘ä»¬æ¢ç”¨å¼ºå¤§çš„papaparser:
```js
export const loadCsv = async (filename) => {
  return new Promise(resolve => {
    const url = `${BASE_URL}${filename}`;

    console.log(`  * Downloading data from: ${url}`);
    Papa.parse(url, {
      download: true,
      header: true,
      complete: (results) => {
        resolve(parseCsv(results['data']));
      }
    })
  });
};
```

æ¨¡å‹è¿˜æ˜¯é‚£ä¸ªæ¨¡å‹ï¼š
```js
export function linearRegressionModel() {
  const model = tf.sequential();
  model.add(tf.layers.dense({inputShape: [bostonData.numFeatures], units: 1}));

  model.summary();
  return model;
};
```

compileçš„è¿‡ç¨‹ä¹Ÿæ˜¯ä¸€æ ·çš„ï¼š
```js
  model.compile(
      {optimizer: tf.train.sgd(LEARNING_RATE), loss: 'meanSquaredError'});
```

è®­ç»ƒçš„è¿‡ç¨‹å› ä¸ºè¦æ›´æ–°UIå˜å¾—æ›´å¤æ‚äº†ä¸€äº›ï¼š
```js
  await model.fit(tensors.trainFeatures, tensors.trainTarget, {
    batchSize: BATCH_SIZE,
    epochs: NUM_EPOCHS,
    validationSplit: 0.2,
    callbacks: {
      onEpochEnd: async (epoch, logs) => {
        await ui.updateModelStatus(
            `Epoch ${epoch + 1} of ${NUM_EPOCHS} completed.`, modelName);
        trainLogs.push(logs);
        tfvis.show.history(container, trainLogs, ['loss', 'val_loss'])

...
      }
    }
  });

  ui.updateStatus('Running on test data...');
  const result = model.evaluate(
      tensors.testFeatures, tensors.testTarget, {batchSize: BATCH_SIZE});
  const testLoss = result.dataSync()[0];
```

æµè§ˆå™¨é‡Œçš„å®Œæ•´ä»£ç è¯·å‚çœ‹ï¼šhttps://github.com/tensorflow/tfjs-examples/blob/master/boston-housing/ï¼Œè¿™é‡Œå¸Œæœ›æ›´å¤šç»™å¤§å®¶ä¸€ä¸ªå®è§‚çš„å°è±¡ï¼Œå°±ä¸æ·±å…¥ç»†èŠ‚äº†ã€‚
